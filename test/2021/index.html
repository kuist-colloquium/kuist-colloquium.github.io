<!DOCTYPE html>
<html lang="ja">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>KUIST Colloquium 2022</title>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
        <link rel="stylesheet" href="/style.css">
    </head>
    <body>
        <header style="background: #00205B;">
            <img src="/C-EL-W.svg" height=45 style="margin: 1em 0em 0em 1em;">
            <h1 style="color: #FFF; text-align: center; font-family: serif; font-size:3em; padding: 0.4em;">
                IST COLLOQUIUM 
2021

            </h1>
        </header>
        <section class="section">
            <div class="container">
                
<p><div class="card" style="width: min(90%, 1200); margin: 50px; margin-left: auto; margin-right: auto; display: block;">
    <div class="card-body" style="overflow:hidden">
        
        <h2 style="border-bottom: solid; margin-bottom:20px; padding-bottom:2px; border-color:#00205B;"><b>信頼されるAIの実現に向けて</b></h2>
        
        
        <div style="float:right; width: max(25%, 130px);">
        <img src="https:&#x2F;&#x2F;trios.tsukuba.ac.jp&#x2F;researcher-picture&#x2F;0000000977.jpg" alt="講演者の画像" style="width:100%; padding: 0px 0px 10px 10px;">
        </div>
        
        <h3 class="card-title" style="margin-bottom: 6px;"><b>佐久間　淳</b></h3>
        <h5 class="card-text" style="margin-bottom: 22px;">筑波大学 情報学群情報科学類 教授</h5>
        
        <p, class="card-text">
        <b>日時</b>：7月8日（木） 
         12時〜13時 
        </p>
        
        <p class="card-text">
        <b>場所</b>：オンライン
        </p>
        
        
        <p class="card-text">AIの急速な発展に伴い、今後はAIが人間や社会にとって重要な判断や意思決定の一部を担うようになることが予想される。このような状況では、単に予測・認識精度が高いだけでなく、AIによる予測は判断が人間によって信頼されるだけのクオリティと根拠が必要となる。AIが信頼されるためには、敵対的環境下での安定性（セキュリティ）や、人権の保護（プライバシ保護、公平性保証）、判断における説明可能性などを必要とする。講演では、信頼されるAIの達成に向けた、一連の研究について紹介する。</p>
        
        
        
            <iframe src="https:&#x2F;&#x2F;player.vimeo.com&#x2F;video&#x2F;575185938" height="480" style="width:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
            
    </div>
</div>

<div class="card" style="width: min(90%, 1200); margin: 50px; margin-left: auto; margin-right: auto; display: block;">
    <div class="card-body" style="overflow:hidden">
        
        <h2 style="border-bottom: solid; margin-bottom:20px; padding-bottom:2px; border-color:#00205B;"><b>機械学習における公平性</b></h2>
        
        
        <div style="float:right; width: max(25%, 130px);">
        <img src="https:&#x2F;&#x2F;www.kamishima.net&#x2F;kamishima.jpg" alt="講演者の画像" style="width:100%; padding: 0px 0px 10px 10px;">
        </div>
        
        <h3 class="card-title" style="margin-bottom: 6px;"><b>神嶌　敏弘</b></h3>
        <h5 class="card-text" style="margin-bottom: 22px;">AIST産業技術総合研究所，人間情報インタラクション研究部門，脳数理研究グループ 主任研究員</h5>
        
        <p, class="card-text">
        <b>日時</b>：9月9日（木） 
         12時〜13時 
        </p>
        
        <p class="card-text">
        <b>場所</b>：オンライン
        </p>
        
        
        <p class="card-text">機械学習やデータマイニングは，与信，採用，保険などの重要な決定に使われるようになってきた．公平性配慮型機械学習は，これらの決定を，人種や性別などのセンシティブ情報に対して公平性を担保した上で行う技術である．公平性に関わる事例を紹介したのち，機械学習で用いられる形式的公平性規準を紹介する．そのあとは，公平性配慮型データマイニングの各種タスクの紹介と，いくつかの代表的手法を紹介する．</p>
        
        
        
            <iframe src="https:&#x2F;&#x2F;player.vimeo.com&#x2F;video&#x2F;611370971" height="480" style="width:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
            
    </div>
</div>

<div class="card" style="width: min(90%, 1200); margin: 50px; margin-left: auto; margin-right: auto; display: block;">
    <div class="card-body" style="overflow:hidden">
        
        <h2 style="border-bottom: solid; margin-bottom:20px; padding-bottom:2px; border-color:#00205B;"><b>セミパラメトリックアプローチによる因果探索</b></h2>
        
        
        <div style="float:right; width: max(25%, 130px);">
        <img src="&#x2F;test&#x2F;shimizu.jpg" alt="講演者の画像" style="width:100%; padding: 0px 0px 10px 10px;">
        </div>
        
        <h3 class="card-title" style="margin-bottom: 6px;"><b>清水　昌平</b></h3>
        <h5 class="card-text" style="margin-bottom: 22px;">滋賀大学 データサイエンス学系 教授</h5>
        
        <p, class="card-text">
        <b>日時</b>：10月7日（木） 
         12時〜13時 
        </p>
        
        <p class="card-text">
        <b>場所</b>：オンライン
        </p>
        
        
        <p class="card-text">因果探索は、変数の因果関係を表す因果グラフをデータから推測する方法論である。古典的な因果探索であるノンパラメトリックアプローチでは、特定の分布や関数形を仮定せずに、因果グラフを推測しようとする。しかし、多くの場合、データから区別できない同値な因果グラフの集合を見つけることしかできない。そこで、より最近のアプローチでは、分布や関数形に何らかの制約をおく。例えば、非ガウス連続分布や線形性などである。このアプローチをここでは、セミパラメトリックアプローチと呼ぶ。このような仮定の下では、因果グラフを一意に識別できたり、ノンパラメトリックアプローチよりも同値な因果グラフの数が少なくできたりする利点がある。<br>本セミナーでは、まず、因果探索におけるセミパラメトリックアプローチとその応用について概観する (<a href="https://www.shimizulab.org/lingam/lingampapers">https://www.shimizulab.org/lingam/lingampapers</a>) 。次に、セミパラメトリック因果探索に関する最近の私達の研究を紹介する。これらは、LiNGAMと呼ばれる線形非ガウス非巡回モデルのアイデアに基づいている。まず、未観測共通原因がある場合に因果グラフを推測する方法を考える。この方法では、未観測共通原因が存在しそうな観測変数のペアを見つけた後、それ以外の観測変数間の因果構造を推定する。もう一つの話題として、異なる条件で得られた複数のデータセットから潜在因子間の因果グラフを探索することを考える。どの潜在因子がすべての条件に共通しており、どの潜在因子が特定の条件に現れるか等を調べることができる。</p>
        
        
        
            <iframe src="https:&#x2F;&#x2F;player.vimeo.com&#x2F;video&#x2F;630697873" height="480" style="width:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
            
    </div>
</div>

<div class="card" style="width: min(90%, 1200); margin: 50px; margin-left: auto; margin-right: auto; display: block;">
    <div class="card-body" style="overflow:hidden">
        
        <h2 style="border-bottom: solid; margin-bottom:20px; padding-bottom:2px; border-color:#00205B;"><b>Adaptive Attention: Bringing Active Vision into the Camera</b></h2>
        
        
        <div style="float:right; width: max(25%, 130px);">
        <img src="https:&#x2F;&#x2F;news.ece.ufl.edu&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;15&#x2F;2020&#x2F;07&#x2F;sanjeev-koppal.jpg" alt="講演者の画像" style="width:100%; padding: 0px 0px 10px 10px;">
        </div>
        
        <h3 class="card-title" style="margin-bottom: 6px;"><b>Sanjeev Koppal</b></h3>
        <h5 class="card-text" style="margin-bottom: 22px;">Associate Professor, ECE Department, University of Florida</h5>
        
        <p, class="card-text">
        <b>日時</b>：12月2日（木） 
         10時〜11時 
        </p>
        
        <p class="card-text">
        <b>場所</b>：オンライン
        </p>
        
        
        <p class="card-text">Most cameras today capture images without considering scene content. In contrast, animal eyes have fast mechanical movements that control how the scene is imaged in detail by the fovea, where visual acuity is highest. The prevalence of active vision during biological imaging, and the wide variety of it, makes it very clear that this is an effective visual design strategy. In this talk, I cover our recent work on creating <b>both</b> new camera designs and novel vision algorithms to enable adaptive and selective active vision and imaging inside cameras and sensors.</p>
        
        
        <b>講演者紹介</b>：Sanjeev Koppal is an Associate Professor at the University of Florida’s Electrical and Computer Engineering Department. He also holds a UF Term Professor Award for 2021-24. Sanjeev is the Director of the FOCUS Lab at UF. Prior to joining UF, he was a researcher at the Texas Instruments Imaging R&amp;D lab. Sanjeev obtained his Masters and Ph.D. degrees from the Robotics Institute at Carnegie Mellon University. After CMU, he was a postdoctoral research associate in the School of Engineering and Applied Sciences at Harvard University. He received his B.S. degree from the University of Southern California in 2003 as a Trustee Scholar. He is a co-author on best student paper awards for ECCV 2016 and NEMS 2018, and work from his FOCUS lab was a CVPR 2019 best-paper finalist. Sanjeev won an NSF CAREER award in 2020 and is an IEEE Senior Member. His interests span computer vision, computational photography and optics, novel cameras and sensors, 3D reconstruction, physics-based vision, and active illumination.
        
        
            <iframe src="https:&#x2F;&#x2F;player.vimeo.com&#x2F;video&#x2F;652322220" height="480" style="width:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
            
    </div>
</div>

<div class="card" style="width: min(90%, 1200); margin: 50px; margin-left: auto; margin-right: auto; display: block;">
    <div class="card-body" style="overflow:hidden">
        
        <h2 style="border-bottom: solid; margin-bottom:20px; padding-bottom:2px; border-color:#00205B;"><b>機械学習・機械発見から見るデータ中心型化学の野望と憂鬱</b></h2>
        
        
        <div style="float:right; width: max(25%, 130px);">
        <img src="https:&#x2F;&#x2F;www.jst.go.jp&#x2F;kisoken&#x2F;presto&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;4&#x2F;2016&#x2F;03&#x2F;10374597.jpg" alt="講演者の画像" style="width:100%; padding: 0px 0px 10px 10px;">
        </div>
        
        <h3 class="card-title" style="margin-bottom: 6px;"><b>瀧川　一学</b></h3>
        <h5 class="card-text" style="margin-bottom: 22px;">理化学研究所 革新知能統合研究センター 研究員</h5>
        
        <p, class="card-text">
        <b>日時</b>：12月9日（木） 
         12時〜13時 
        </p>
        
        <p class="card-text">
        <b>場所</b>：オンライン
        </p>
        
        
        <p class="card-text">この発表では化学を例に機械学習屋から見た自然科学研究における「機械学習・機械発見技術の力」の光明面と暗黒面を概観する。化学はある分子A(例えば二酸化炭素)を別の分子B(例えばアルコール)に変える方法を研究する。私たちの身の回りの材料・医薬品・エネルギーなどに加え、あらゆる生命現象も化学反応の産物であり、その波及範囲は学術上も産業上も広大である。しかし現在の化学は依然として経験科学的な側面が強く、ご多分にもれず機械学習の利活用が現在盛んに研究されるようになった。化学は主役である分子や化学反応が「組合せ的対象」である点とその組合せを制約する「第一原理(量子力学)が分かっている」点により、情報科学者にとっても面白い問題の宝庫である。私たちを熱中させるに足る技術上の研究課題には事欠かない一方で、新しい反応〜実際にAをBに変える方法〜の実現は依然として超絶的に困難なままで「自在な化学反応の設計・発見」への道のりは遠い。機械学習×化学というトピックの何が面白いのか、なぜそんなに難しいのか、を様々な自然科学研究に携わってきた機械学習屋の視点から紹介する。</p>
        
        
        
            <iframe src="https:&#x2F;&#x2F;player.vimeo.com&#x2F;video&#x2F;656871480" height="480" style="width:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
            
    </div>
</div>
</p>


            </div>
        </section>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    </body>
</html>
